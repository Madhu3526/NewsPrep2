{
  "title": "Google Gemini is getting better at identifying AI fakes",
  "text": "is a news editor with over a decade’s experience in journalism. He previously worked at Android Police and Tech Advisor.\n\nPosts from this author will be added to your daily email digest and your homepage feed.\n\nGoogle is making it easier for Gemini users to detect at least some AI-generated content. From today, you’ll be able to use the Gemini app to determine if an image was either created or edited by a Google AI tool, simply by asking Gemini “Is this AI-generated?”\n\nWhile the initial launch is limited to images, Google says verification of video and audio will come “soon,” and it also intends to expand the functionality beyond the Gemini app, including into Search.\n\nThe more important expansion will come further down the line, when Google extends verification to support industry-wide C2PA content credentials. The initial image verification is based only on SynthID, Google’s own invisible AI watermarking, but an expansion to C2PA would make it possible to detect the source of content generated by a wider variety of AI tools and creative software, including OpenAI’s Sora.\n\nGoogle also announced that images generated by its Nano Banana Pro model, also revealed today, will have C2PA metadata embedded. It’s the second bit of good news for C2PA this week, after TikTok confirmed it would use C2PA metadata as part of its own invisible watermarking for AI-generated content.\n\nManual content verification in Gemini is a useful step, but C2PA credentials, and other watermarks like SynthID, won’t be truly useful until social media platforms get better at flagging AI-generated content automatically, rather than putting the onus on users to confirm for themselves.",
  "authors": [
    "Dominic Preston"
  ],
  "url": "https://www.theverge.com/news/824786/google-gemini-synthid-ai-image-detection"
}
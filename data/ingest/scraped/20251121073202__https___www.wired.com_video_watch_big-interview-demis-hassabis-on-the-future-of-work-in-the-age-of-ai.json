{
  "title": "Demis Hassabis On The Future of Work in the Age of AI",
  "text": "Transcript\n\nIt's a very intense time in the field.\n\nWe obviously want all\n\nof the brilliant things these AI systems can do,\n\ncome up with new cures for diseases, new energy sources,\n\nincredible things for humanity.\n\nThat's the promise of AI.\n\nBut also, there are worries\n\nif the first AI systems are built\n\nwith the wrong value systems or they're built unsafely,\n\nthat could be also very bad.\n\nWired sat down with Demis Hassabis,\n\nwho's the CEO of Google DeepMind, which is the engine\n\nof the company's artificial intelligence.\n\nHe's a Nobel Prize winner and also a knight.\n\nWe discussed AGI, the future of work,\n\nand how Google plans to compete in the age of AI.\n\nThis is The Big Interview.\n\n[upbeat music]\n\nWell, welcome to The Big Interview, Demis.\n\nThank you, thanks for having me.\n\nSo let's start talking about AGI a little here.\n\nNow, you founded DeepMind with the idea\n\nthat you would solve intelligence and then use intelligence\n\nto solve everything else.\n\nAnd I think it was like a 20-year mission.\n\nWe're like 15 years into it, and you're on track?\n\nI feel like, yeah,\n\nwe're pretty much dead on track, actually,\n\nis what would be our estimate.\n\nThat means five years away\n\nfrom what I guess people will call AGI.\n\nYeah, I think in the next five to 10 years,\n\nthat would be maybe 50% chance\n\nthat we'll have what we are defined as AGI, yes.\n\nWell, some of your peers are saying,\n\nTwo years, three years,\n\nand others say a little more, but that's really close,\n\nthat's really soon.\n\nHow do we know that we're that close?\n\nThere's a bit of a debate going on in the moment\n\nin the field about definitions of AGI,\n\nand then obviously, of course, dependent on that.\n\nThere's different predictions for when it will happen.\n\nWe've been pretty consistent from the very beginning.\n\nAnd actually, Shane Legg,\n\none of my co-founders and our chief scientist,\n\nyou know, he helped define the term AGI back in, I think,\n\nearly 2001 type of timeframe.\n\nAnd we've always thought about it as system\n\nthat has the ability to exhibit,\n\nsort of all the cognitive capabilities we have as humans.\n\nAnd the reason that's important,\n\nthe reference to the human mind,\n\nis the human mind is the only existence proof we have.\n\nMaybe in the universe, the general intelligence is possible.\n\nSo if you want to claim sort of general intelligence, AGI,\n\nthen you need to show that it generalizes\n\nto all these domains.\n\nIs when everything's filled in,\n\nall the check marks are filled in, then we have it-\n\nYes, so I think there are missing capabilities right now.\n\nYou know, that all of us\n\nwho have used the latest sort of LLMs and chatbots,\n\nwill know very well, like on reasoning,\n\non planning, on memory.\n\nI don't think today's systems can invent, you know,\n\ndo true invention,\n\nyou know, true creativity,\n\nhypothesize new scientific theories.\n\nThey're extremely useful, they're impressive,\n\nbut they have holes.\n\nAnd actually, one of the main reasons I don't think\n\nwe are at AGI yet is\n\nbecause of the consistency of responses.\n\nYou know, in some domains,\n\nwe have systems that can do International Math Olympiad,\n\nmath problems to gold medal standard-\n\nSure. With our AlphaFold system.\n\nBut on the other hand,\n\nthese systems sometimes still trip up on high school maths\n\nor even counting the number of letters in a word.\n\nYeah. So that to me is not\n\nwhat you would expect.\n\nThat level of sort of difference\n\nin performance across the board is not consistent enough,\n\nand therefore shows\n\nthat these systems are not fully generalizing yet.\n\nBut when we get it,\n\nis it then like a phase shift that, you know,\n\nthen all of a sudden things are different,\n\nall the check marks are checked?\n\nYeah. You know,\n\nand we have a thing that can do everything.\n\nMm-hmm.\n\nAre we then power in a new world?\n\nI think, you know, that again,\n\nthat is debated, and it's not clear to me\n\nwhether it's gonna be more\n\nof a kind of incremental transition versus a step function.\n\nMy guess is, it looks like it's gonna be more\n\nof an incremental shift.\n\nEven if you had a system like that, the physical world,\n\nstill operates with the physical laws,\n\nyou know, factories, robots, these other things.\n\nSo it'll take a while for the effects of that, you know,\n\nthis sort of digital intelligence, if you like,\n\nto really impact, I think, a lot of the real world things.\n\nMaybe another decade plus,\n\nbut there's other theories on that too,\n\nwhere it could come faster.\n\nYeah, Eric Schmidt, who I think used to work at Google,\n\nhas said that, It's almost like a binary thing.\n\nHe says, If China, for instance, gets AGI,\n\nthen we're cooked.\n\nBecause if someone gets it like 10 minutes,\n\nbefore the next guy, then you can never catch up.\n\nYou know, because then it'll maintain bigger,\n\nbigger leads there.\n\nYou don't buy that, I guess.\n\nI think it's an unknown.\n\nIt's one of the many unknowns,\n\nwhich is that, you know,\n\nthat's sometimes called the hard takeoff scenario,\n\nwhere the idea there is that these AGI systems,\n\nthey're able to self-improve,\n\nmaybe code themselves future versus themselves,\n\nthat maybe they're extremely fast at doing that.\n\nSo what would be a slight lead,\n\nlet's say, you know, a few days,\n\ncould suddenly become a chasm if that was true.\n\nBut there are many other ways it could go too,\n\nwhere it's more incremental.\n\nSome of these self-improvement things are not able\n\nto kind of accelerate in that way,\n\nthen being around the same time,\n\nwould not make much difference.\n\nBut it's important, I mean,\n\nthese issues are the geopolitical issues.\n\nI think the systems that are being built,\n\nthey'll have some imprint of the values\n\nand the kind of norms of the designers and the culture\n\n[Steven] that they were embedded in. Mm-hmm.\n\nSo, you know, I think it is important,\n\nthese kinds of international questions.\n\nSo when you build AI at Google,\n\nyou know, you have that in mind.\n\nDo you feel competitive imperative to, in case that's true,\n\nOh my God, we better be first?\n\nIt's a very intense time at the moment in the field\n\nas everyone knows.\n\nThere's so many resources going into it, lots of pressures,\n\nlots of things that need to be researched.\n\nAnd there's sort of lots of different types\n\nof pressures going on.\n\nWe obviously want all of the brilliant things\n\nthat these AI systems can do.\n\nYou know, I think eventually,\n\nwe'll be able to advance medicine and science with it,\n\nlike we've done with AlphaFold,\n\ncome up with new cures for diseases, new energy sources,\n\nincredible things for humanity, that's the promise of AI.\n\nBut also there are worries both in terms of, you know,\n\nif the first AI systems are built\n\nwith the wrong value systems or they're built unsafely,\n\nthat could be also very bad.\n\nAnd, you know, there are at least two risks\n\nthat I worry a lot about.\n\nOne is, bad actors in whether it's individuals\n\nor rogue nations repurposing general purpose AI technology\n\nfor harmful lens.\n\nAnd then the second one is, obviously,\n\nthe technical risk of AI itself.\n\nAs it gets more and more powerful,\n\nmore and more agentic,\n\ncan we make sure the guardrails are safe around it?\n\nThey can't be circumvented.\n\nAnd that interacts with this idea of, you know,\n\nwhat are the first systems that are built\n\nby humanity gonna be like?\n\nThere's commercial imperative-\n\n[Steven] Right. There's national imperative,\n\nand there's a safety aspect to worry\n\nabout who's in the lead and where those projects are.\n\nA few years ago, the companies were saying,\n\nPlease, regulate us.\n\nWe need regulation. Mm-hmm, mm-hmm.\n\nAnd now, in the US at least,\n\nthe current administration seems less interested\n\nin putting regulations on AI than accelerating it\n\nso we can beat the Chinese.\n\nAre you still asking for regulation?\n\nDo you think that that's a miss on our part?\n\nI think, you know,\n\nand I've been consistent in this,\n\nI think there are these other geopolitical sort of overlays\n\nthat have to be taken into account,\n\nand the world's a very different place\n\nto how it was five years ago in many dimensions.\n\nBut there's also, you know,\n\nI think the idea of smart regulation\n\nthat makes sense around these increasingly powerful systems,\n\nI think is gonna be important.\n\nI continue to believe that.\n\nI think though, and I've been certain on this as well,\n\nit sort of needs to be international,\n\nwhich looks hard at the moment\n\nin the way the world is working,\n\nbecause these systems, you know,\n\nthey're gonna affect everyone,\n\nand they're digital systems. Yeah.\n\nSo, you know, if you sort of restrict it in one area,\n\nthat doesn't really help\n\nin terms of the overall safety\n\nof these systems getting built for the world\n\n[Steven] and as a society. Yeah.\n\nSo that's the bigger problem, I think,\n\nis some kind of international cooperation or collaboration,\n\nI think, is what's required.\n\nAnd then smart regulation, nimble regulation\n\nthat moves as the knowledge\n\nabout the research becomes better and better.\n\nWould it ever reach a point for you where you would feel,\n\nMan, we're not putting the guardrails in.\n\nYou know, we're competing, that we really have to stop,\n\nor you can't get involved in that?\n\nI think a lot of the leaders of the main labs,\n\nat least the western labs,\n\nyou know, there's a small number of them\n\nand we do all know each other\n\nand talk to each other regularly.\n\nAnd a lot of the lead researchers do.\n\nThe problem is, is that it's not clear\n\nwe have the right definitions to agree when that point is.\n\nLike, today's systems,\n\nalthough they're impressive as we discussed earlier,\n\nthey're also very flawed.\n\nAnd I don't think today's systems,\n\nare posing any sort of existential risk.\n\nMm-hmm. So it's still theoretical,\n\nbut the problem is that a lot of unknowns,\n\nwe don't know how fast those will come,\n\nand we don't know how risky they will be.\n\nBut in my view, when there are so many unknowns,\n\nthen I'm optimistic we'll overcome them.\n\nAt least technically,\n\nI think the geopolitical questions could be actually,\n\nend up being trickier, given enough time and enough care\n\nand thoughtfulness, you know,\n\nsort of using the scientific method\n\nas we approach this AGI point.\n\nThat makes perfect sense.\n\nBut on the other hand, if that timeframe is there,\n\nwe just don't have much time, you know?\n\nNo, we don't.\n\nWe don't have much time.\n\nI mean, we're increasingly putting resources into security\n\nand things like cyber,\n\nand also research into controllability\n\nand understanding of these systems,\n\nsometimes called mechanistic interpretability.\n\nYou know, there's a lot of different sub-branches of AI.\n\nYeah, that's right.\n\nI wanna get to interpretability.\n\nYeah, that are being invested in,\n\nand I think even more needs to happen.\n\nAnd then at the same time,\n\nwe need to also have societal debates more\n\nabout institutional building.\n\nHow do we want governance to work?\n\nHow are we gonna get international agreement,\n\nat least on some basic principles,\n\naround how these systems are used and deployed\n\nand also built?\n\nWhat about the effect on work on the marketplace?\n\nYeah. You know,\n\nhow much do you feel that AI is going\n\nto change people's jobs,\n\nyou know, the way jobs are distributed in the workforce?\n\nI don't think we've seen,\n\nmy view is if you talk to economists,\n\nthey feel like there's not much has changed yet.\n\nYou know, people are finding these tools useful,\n\ncertainly in certain domains-\n\n[Steven] Yeah. Like, things like AlphaFold,\n\nmany, many scientists are using it to accelerate their work.\n\nSo it seems to be additive at the moment.\n\nWe'll see what happens over the next five, 10 years.\n\nI think there's gonna be a lot of change\n\nwith the jobs world, but I think as in the past,\n\nwhat generally tends to happen is new jobs are created\n\nthat are actually better,\n\nthat utilize these tools or new technologies,\n\nwhat happened with the internet, what happened with mobile?\n\nWe'll see if it's different this time.\n\nYeah.\n\nObviously everyone always thinks this new one,\n\nwill be different.\n\nAnd it may be, it will be,\n\nbut I think for the next few years,\n\nit's most likely to be, you know,\n\nwe'll have these incredible tools\n\nthat supercharge our productivity,\n\nmake us really useful for creative tools,\n\nand actually almost make us a little bit superhuman\n\nin some ways in what we're able to produce individually.\n\nSo I think there's gonna be a kind of golden era,\n\nover the next period of what we're able to do.\n\nWell, if AGI can do everything humans can do,\n\nthen it would seem that they could do the new jobs too.\n\nThat's the next question about like, what AGI brings.\n\nBut, you know, even if you have those capabilities,\n\nthere's a lot of things I think we won't want to do\n\nwith a machine.\n\nYou know, I sometimes give this example\n\nof doctors and nurses.\n\nYou know, maybe a doctor\n\nand what the doctor does and the diagnosis,\n\nyou know, one could imagine that being helped by AI tool\n\nor even having an AI kind of doctor.\n\nOn the other hand, like nursing,\n\nyou know, I don't think you'd want a robot to do that.\n\nI think there's something\n\nabout the human empathy aspect of that and the care,\n\nand so on, that's particularly humanistic.\n\nI think there's lots of examples like that\n\nbut it's gonna be a different world for sure.\n\nIf you would talk to a graduate now,\n\nwhat advice would you give\n\nto keep working- Yeah.\n\nThrough the course\n\nof a lifetime- Yeah.\n\nYou know, in the age of AGI?\n\nMy view is, currently,\n\nand of course, this is changing all the time\n\nwith the technology developing.\n\nBut right now, you know,\n\nif you think of the next five, 10 years as being,\n\nthe most productive people might be 10X more productive\n\nif they are native with these tools.\n\nSo I think kids today, students today,\n\nmy encouragement would be immerse yourself\n\nin these new systems, understand them.\n\nSo I think it's still important\n\nto study STEM and programming and other things,\n\nso that you understand how they're built,\n\nmaybe you can modify them yourself\n\non top of the models that are available.\n\nThere's lots of great open source models and so on.\n\nAnd then become, you know,\n\nincredible at things like fine-tuning, system prompting,\n\nyou know, system instructions,\n\nall of these additional things that anyone can do.\n\nAnd really know how to get the most out of those tools,\n\nand do it for your research work, programming,\n\nand things that you are doing on your course.\n\nAnd then come out of that being incredible\n\nat utilizing those new tools\n\nfor whatever it is you're going to do.\n\nLet's look a little beyond the five and 10-year range.\n\nTell me what you envision when you look at our future\n\nin 20 years, in 30 years, if this comes about,\n\nwhat's the world like when AGI is everywhere?\n\nWell, if everything goes well,\n\nthen we should be in an era of what I like\n\nto call sort of radical abundance.\n\nSo, you know, AGI solves some of these key,\n\nwhat I sometimes call root node problems\n\nin the world facing society.\n\nSo a good one, examples would be curing diseases,\n\nmuch healthier, longer lifespans,\n\nfinding new energy sources,\n\nyou know, whether that's optimal batteries\n\nand better room temperature, superconductors, fusion.\n\nAnd then if that all happens,\n\nthen we know it should be a kind of era\n\nof maximum human flourishing where we travel to the stars\n\nand colonize the galaxy.\n\nYou know, I think the beginning of that will happen\n\nin the next 20, 30 years if the next period goes well.\n\nI'm a little skeptical of that.\n\nI think we have an unbelievable abundance now,\n\nbut we don't distribute it,\n\nyou know, fairly. Yeah.\n\nI think that we kind of know\n\nhow to fix climate change, right?\n\nWe don't need a AGI to tell us how to do it,\n\nyet we're not doing it. I agree with that.\n\nI think we being as a species,\n\na society not good at collaborating,\n\nand I think climate is a good example.\n\nBut I think we are still operating,\n\nhumans are still operating in a zero-sum game mentality.\n\nBecause actually, the earth is quite finite,\n\nrelative to the amount of people there are now\n\nin our cities.\n\nAnd I mean, this is why our natural habitats,\n\nare being destroyed,\n\nand it's affecting wildlife and the climate\n\n[Steven] and everything. Yeah.\n\nAnd it's also partly 'cause people are not willing\n\nto accept, we do now to figure out climate.\n\nBut it would require people to make sacrifices.\n\nYeah. And people don't want to.\n\nBut this radical abundance would be different.\n\nWe would be in a finally, like,\n\nit would feel like a non-zero-sum game.\n\nHow will we get [indistinct] to that?\n\nLike, you talk about diseases-\n\nWell, I gave you an example. We have vaccines,\n\nand now some people think we shouldn't use it.\n\nLet me give you a very simple example.\n\nSure. Water access.\n\nThis is gonna be a huge issue in the next 10, 20 years.\n\nIt's already an issue.\n\nCountries in different, you know,\n\npoorer parts of the world, dryer parts of the world,\n\nalso obviously compounded by climate change.\n\n[Steven] Yeah.\n\nWe have a solution to water access.\n\nIt's desalination, it's easy.\n\nThere's plenty of sea water. Yeah.\n\nAlmost all countries have a coastline.\n\nBut the problem is, it's salty water,\n\nbut desalination only very rich countries.\n\nSome countries do do that, use desalination\n\nas a solution to their fresh water problem,\n\nbut it costs a lot of energy. Mm-hmm.\n\nBut if energy was essentially zero,\n\nthere was renewable free clean energy, right?\n\nLike fusion, suddenly, you solve the water access problem.\n\nWater is, who controls a river\n\nor what you do with that does not,\n\nit becomes much less important than it is today.\n\nI think things like water access,\n\nyou know, if you run forward 20 years,\n\nand there isn't a solution like that, could lead\n\nto all sorts of conflicts,\n\nprobably that's the way it's trending-\n\nMm-hmm, right. Especially if you include\n\nfurther climate change.\n\nSo- And there's many,\n\nmany examples like that.\n\nYou could create rocket fuel easily-\n\nMm-hmm. Because you just separate\n\nthat from seawater, hydrogen and oxygen.\n\nIt's just energy again.\n\nSo you feel that these problems get solved by AGI, by AI,\n\nthen we're going to, our outlook will change,\n\nand we will be- That's what I hope.\n\nYes, that's what I hope.\n\nBut that's still a secondary part.\n\nSo the AGI will give us the radical abundance capability,\n\ntechnically, like the water access.\n\nYeah. I then hope,\n\nand this is where I think we need some great philosophers\n\nor social scientists to be involved.\n\nThat should hopefully shift our mindset\n\nas a society to non-zero-sum.\n\nYou know, there's still the issue\n\nof do you divide even the radical abundance fairly, right?\n\nOf course, that's what should happen.\n\nBut I think there's much more likely,\n\nonce people start feeling and understanding\n\nthat there is this almost limitless supply of raw materials\n\nand energy and things like that.\n\nDo you think that driving this innovation\n\nby profit-making companies is the right way to go?\n\nWe're most likely to reach\n\nthat optimistic high point through that?\n\nI think it's the current capitalism\n\nor, you know, is the current\n\nor the western sort of democratic kind of systems,\n\nhave so far been proven\n\nto be sort of the best drivers of progress.\n\nMm-hmm. So I think that's true.\n\nMy view is that once you get\n\nto that sort of stage of radical abundance and post-AGI,\n\nI think economics starts changing,\n\neven the notion of value and money.\n\nAnd so again, I think we need,\n\nI'm not sure why economists are not working harder on this\n\nif maybe they don't believe it's that close, right?\n\nBut if they really did that, like the AGI scientists do,\n\nthen I think there's a lot\n\nof economic new economic theory that's required.\n\nYou know, one final thing,\n\nI actually agree with you that this is so significant\n\nand is gonna have a huge impact.\n\nBut when I write about it,\n\nI always get a lot of response from people\n\nwho are really angry already about artificial intelligence\n\nand what's happening.\n\nHave you tasted that?\n\nHave you gotten that pushback and anger by a lot of people?\n\nIt's almost like the industrial revolution people-\n\nYeah. Fighting back.\n\nI mean, I think that anytime there's,\n\nI haven't personally seen a lot of that,\n\nbut obviously, I've read and heard a lot about,\n\nand it's very understandable.\n\nThat's all that's happened many times.\n\nAs you say, industrial revolution,\n\nwhen there's big change,\n\n[Steven] a big revolution. Yeah.\n\nAnd I think this will be at least\n\nas big as the industrial revolution, probably a lot bigger.\n\nThat's surprising, there's unknowns,\n\nit's scary, things will change.\n\nBut on the other hand,\n\nwhen I talk to people about the passion,\n\nthe why I'm building AI- Mm-hmm.\n\nWhich is to advance science\n\nand medicine- Right.\n\nAnd understanding of the world around us.\n\nAnd then I explain to people, you know,\n\nand I've demonstrated, it's not just talk.\n\nHere's AlphaFold, you know,\n\nNobel Prize winning breakthrough,\n\ncan help with medicine and drug discovery.\n\nObviously, we're doing this with isomorphic now\n\nto extend it into drug discovery,\n\nand we can cure terrible diseases\n\nthat might be afflicting your family.\n\nSuddenly, people are like,\n\nWell, of course, we need that.\n\nRight. It'll be immoral not\n\nto have that if that's within our grasp.\n\nAnd the same with climate and energy.\n\nYeah. You know,\n\nmany of the big societal problems,\n\nit's not like you know,\n\nwe know, we've talked about,\n\nthere's many big challenges facing society today.\n\nAnd I often say I would be very worried about our future\n\nif I didn't know something\n\nas revolutionary as AI was coming down the line\n\nto help with those other challenges.\n\nOf course, it's also a challenge itself, right?\n\nBut at least, it's one of these challenges\n\nthat can actually help with the others if we get it right.\n\nWell, I hope your optimism holds out and is justified.\n\nThank you so much. And I'll do my best.\n\nThank you.\n\n[upbeat music]",
  "authors": [
    "Cond√© Nast"
  ],
  "url": "https://www.wired.com/video/watch/big-interview-demis-hassabis-on-the-future-of-work-in-the-age-of-ai"
}
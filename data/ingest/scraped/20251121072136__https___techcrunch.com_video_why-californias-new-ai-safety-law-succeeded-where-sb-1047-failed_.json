{
  "title": "Why California’s new AI safety law succeeded where SB 1047 failed",
  "text": "California just made history as the first state to require AI safety transparency from the biggest labs in the industry. Governor Newsom signed SB 53 into law this week, mandating that AI giants like OpenAI and Anthropic disclose, and stick to, their safety protocols. The decision is already sparking debate about whether other states will follow suit.\n\nAdam Billen, vice president of public policy at Encode AI, joined Equity to break down what California’s new AI transparency law actually means — from whistleblower protections to safety incident reporting requirements. He also explains why SB 53 succeeded where SB 1047 failed, what “transparency without liability” looks like in practice, and what’s still on Governor Newsom’s desk, including rules for AI companion chatbots.\n\nEquity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.\n\nSubscribe to us on Apple Podcasts, Overcast, Spotify and all the casts. You also can follow Equity on X and Threads, at @EquityPod.",
  "authors": [
    "Theresa Loconsolo",
    "Audio Producer",
    "Sarah Perez",
    "Julie Bort",
    "Lorenzo Franceschi-Bicchierai",
    "Ram Iyer",
    "Connie Loizos",
    "Anthony Ha",
    "Rebecca Bellan",
    "Aisha Malik"
  ],
  "url": "https://techcrunch.com/video/why-californias-new-ai-safety-law-succeeded-where-sb-1047-failed/"
}
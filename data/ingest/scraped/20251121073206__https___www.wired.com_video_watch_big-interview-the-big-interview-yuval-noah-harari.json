{
  "title": "Yuval Noah Harari Sees the Future of Humanity, AI, and Information",
  "text": "Transcript\n\nDo you think you will be able\n\nto trust the super intelligent ais that you're developing?\n\nAnd then they answer Yes.\n\nAnd this is almost insane\n\nbecause the same people who cannot trust other people,\n\nfor some reason,\n\nthey think they could trust these alien ais.\n\n[upbeat music]\n\nSo welcome to the Wired big interview.\n\nThank you. It's good to be here.\n\nAnd that, I believe the main theme of the,\n\nyour new book Nexus.\n\nYes.\n\nSo we would like to know how should we live\n\nwith especially that AI\n\nor you know, super intelligence in the\n\nsociety in the future.\n\nThe first question in the late nineties, actually,\n\nthere is a one idea that, that if the internet will split,\n\nyou know, globally, and then\n\nit'll bring the world to peace,\n\nbecause the information will tell the truth,\n\nand every people could get access to the every information\n\nand maybe multi understanding will grow.\n\nAnd finally, the human being becoming wiser.\n\nHowever, you said that such a view of information,\n\nit's more like naive.\n\nYeah. Could you explain why?\n\nYes, because information is not truth.\n\nMost information is not about representing\n\nreality in a truthful way.\n\nThe main function of information is to connect a lot\n\nof things together, to connect people together.\n\nAnd you sometimes can connect people with the truth,\n\nbut it's often easier to do it with fiction\n\nand fantasy and so forth.\n\nSome of the most important texts in history,\n\nyou know, like the Bible,\n\nHmm.\n\nThey connect millions of people together,\n\nbut not necessarily by telling them the truth.\n\nIn a completely free market of information,\n\nmost information will be fiction or fantasy, or even lies\n\nbecause the truth is costly.\n\nWhereas fiction is cheap.\n\nTo write a truthful account of anything, of history,\n\nof economics, of physics, you need to invest time and effort\n\nand money to gather evidence to fact check.\n\nIt's costly.\n\nWhereas fiction can be made as simple\n\nas you would like it to be.\n\nAnd finally, the truth is often painful or unpleasant.\n\nWhereas fiction can be made as pleasant\n\nand attractive as you would like it to be.\n\nSo in a completely free market of information,\n\ntruth will be flooded, overwhelmed\n\nby enormous amounts of fictions and fantasies.\n\nThis is what we saw with the internet,\n\nthat it was a completely free market of information\n\nand very quickly the expectations\n\nthat the internet will just spread facts and truth\n\nand agreement between people turned\n\nout to be completely naive.\n\nRecently, Bill Gates\n\nand the interview of the New Yorker,\n\ninitially he thought the digital technology will actually\n\nempower the people.\n\nBut finally he realized\n\nthat social networkings is totally different than the\n\nprevious digital technologies.\n\nAnd he said he relied too late.\n\nAnd he also said\n\nthat the AI is also the totally different technology\n\nthan the previous one.\n\nAnd if ai, it's totally different than\n\nwhat the technology we have previously is\n\nanything we could learn from the history if there is nothing\n\nequivalent to the ai.\n\nAnd the most important thing to understand is\n\nthat AI is an agent and not a tool.\n\nI see. Previous information\n\ntechnologies, I mean,\n\nI hear many people say the AI revolution,\n\nit's like the print revolution\n\nor it's like the invention of writing.\n\nAnd this is a misunderstanding\n\nbecause all these previous information technologies,\n\nthey were tool in our hands.\n\nIf you invent a printing press, you still need a human being\n\nto write all the texts.\n\nAnd you need a human being to decide what books to print.\n\nAI is fundamentally different.\n\nIt is an agent, it can write books by itself.\n\nIt can decide by itself to disseminate these ideas\n\nor those ideas, and it can also create entirely new\n\nideas by itself.\n\nAnd this is something unprecedented in history\n\nbecause we never had to deal with a super intelligent agent,\n\nbut there were of course other agents in the world like\n\nanimals, but we were more intelligent than the animals.\n\nWe were especially better than the animals at connecting.\n\nWhy do we control the planet?\n\nBecause we can create networks of thousands\n\nand then millions\n\nand then billions of people\n\nwho don't know each other personally,\n\nBut can nevertheless cooperate effectively.\n\n10 chimpanzees can cooperate\n\nbecause among chimpanzees,\n\ncooperation is based on intimate knowledge.\n\nOne of the other, But a thousand chimpanzees cannot\n\ncooperate because they don't know each other.\n\nA thousand humans can cooperate.\n\nEven a million humans\n\nor a hundred million humans,\n\nlike Japan today has more than 100 million citizens.\n\nMost of them don't know each other.\n\nNevertheless, you can cooperate with them.\n\nHow come that humans manage\n\nto cooperate in such large numbers\n\nbecause they know how to invent stories and shared stories.\n\nReligion is one obvious example.\n\nMoney is probably the most successful story ever told.\n\nAgain, it's just a story.\n\nI mean, you look at a piece of paper,\n\nyou look at at at a coin, it has no objective value.\n\nIt can nevertheless help people connect and cooperate\n\nbecause we all believe the same stories about money.\n\nAnd this is something\n\nthat gave us an advantage over chimpanzees\n\nand horses and elephants.\n\nNone of them can invent stories like money.\n\nBut AI can, which again,\n\nthe emphasis on intelligence may not be a,\n\na very may be misleading.\n\nOkay. The key point about ai,\n\nit can invent new stories like new, maybe new kinds\n\nof money and it can create networks\n\nof cooperation better than us.\n\nSo you mentioned a lot about the religion.\n\nThe important things is that you wrote in the book\n\nthat those kind of, the, you know,\n\nacceptance vision itself of the religion\n\nwill affect about the acceptance of AI itself.\n\nYes.\n\nIn the Japanese or Asian way of, in animism way, we accept\n\nnaturally more like a area intrusions living together\n\nin the same environment or like I would say multi-species\n\nthings. Yes.\n\nMaybe it's vulnerable to accept about what AI\n\nwill tell or something.\n\nBut could you tell if also the advantage\n\nof the those things?\n\nWhat would you say?\n\nWell, I think that the basic attitude towards the AI\n\nrevolution should be one of that avoids the extremes\n\nof either being terrified that AI is coming\n\nand will destroy all of us,\n\nbut also to avoid the extreme of being overconfident.\n\nI see. That,\n\noh, ai, it'll improve medicine\n\nand it will improve the education.\n\nIt'll create a good world.\n\nWe need a middle path of first of all,\n\nsimply understanding the magnitude\n\nof the change we are facing.\n\nThat all the previous revolutions in history\n\npale in comparison with this revolution.\n\nBecause again, throughout history,\n\nevery time we invent something,\n\nso we still have human beings making all the decisions.\n\nSo for instance, in the financial system,\n\nI just recently read an article in Wired\n\nabout an AI that created the religion\n\nand wrote a holy book of the new religion and also created\n\nor helped to spread a new cryptocurrency.\n\nAnd it now has in theory, $40 million dollars,\n\nthis AI. Wow.\n\nNow what happens?\n\nIf AIs start to have money,\n\nstart to have money of their own,\n\nand the ability to make decisions about how\n\nto use it if they start investing money in\n\nthe stock exchange.\n\nSo suddenly to understand\n\nwhat is happening in the financial system, you need\n\nto understand not just the ideas of human beings.\n\nYou also need to understand the ideas of ai.\n\nAnd AI can create ideas which will be\n\nunintelligible to us.\n\nHmm. The horses\n\ncould not understand the human ideas about money.\n\nI see. So I\n\ncan sell you a horse for money.\n\nThe horse doesn't understand what is happening.\n\nHmm. Because\n\nthe horse doesn't understand money.\n\nThe same thing might happen now,\n\nbut we will be like the horses, the horses and elephants.\n\nThey cannot understand the human political system\n\nor the human financial system that controls their destiny.\n\nThat the decisions about our lives will be made by a network\n\nof highly intelligent ais that we simply can't understand.\n\nHmm.\n\nThe AI trust network, we can't understand.\n\nAnd sometimes we say those things as not singularity,\n\nnot only singularity, but hyper object.\n\nLike hyper object means what we, you can't understand.\n\nAnd that's context often said in environment things,\n\nyou know, that the nature of the kind of system earth\n\nwe can't understand fully.\n\nSo, you know, human being really struggling about how\n\nto deal with, adapt with those change of the climate\n\nor you know, the big systems\n\nand maybe the AI is just coming up to the top list of\n\nhow could we deal with how human being could do, you know,\n\nmake being flexibility\n\nor even just deal with those hyper object\n\nor just a singularity.\n\nHow could we do that?\n\nYou know, if you can't understand fully,\n\nIdeally, we should be able to trust the ais\n\nto help us deal with these hyper object,\n\nwith higher complex realities, which are\n\nbeyond our understanding.\n\nBut the big paradox of the AI revolution,\n\nI think is the, the paradox of trust.\n\nWe are now in the midst of an accelerating AI race\n\nwith different companies\n\nand different countries rushing as fast as possible\n\nto develop more and more powerful ais.\n\nNow, when you talk with the people\n\nwho lead the AI revolution with the entrepreneurs,\n\nwith the business people, with the heads of\n\nthe government and you ask them, why are you moving so fast?\n\nHmm. They almost\n\nall say that we know it's risky,\n\nwe understand it's dangerous,\n\nwe understand it would be wiser to move more slowly\n\nand to invest more in safety.\n\nBut the other company\n\nor the other country doesn't slow down.\n\nThey will win the race.\n\nYeah. They will\n\ndevelop super intelligent AI first\n\nand they will then dominate the world.\n\nThey will conquer the world and we cannot trust them.\n\nThis is why we must move as fast as possible.\n\nNow you ask them a second question, you ask them,\n\ndo you think you will be able\n\nto trust the super intelligent ais that you're developing?\n\nAnd then they answer yes.\n\nAnd this is almost insane\n\nbecause the same people who cannot trust other people.\n\nYeah. For some reason\n\nthey think they could trust these alien ais.\n\nYes. You know,\n\nwe have thousands of years of experience\n\nwith human beings.\n\nWe have some good understanding of human psychology,\n\nhuman politics.\n\nWe understand the human craving for power,\n\nbut we also understand how to check the pursuit of power.\n\nAnd how to build trust between humans, with ais,\n\nwith super intelligent ais.\n\nWe have no experience at all.\n\nI see.\n\nSo this situation, the the safest thing would be\n\nto first of all, build more trust with other humans.\n\nHumans. So it's amazing\n\nthat today we have these networks\n\nof trust in which hundreds of millions\n\nof people cooperate on a regular basis.\n\nAnd there is no such thing as a completely free market.\n\nSome things can be created successfully\n\nby competition in a free market.\n\nWe know that.\n\nBut there are certain services,\n\ngoods, essentials that cannot be maintained just\n\nby competition in a free market.\n\nJustice is one example.\n\nLet's say it's a free market.\n\nI sign a business contract with you,\n\nand then I break the contract.\n\nSo we go to a judge, we go to a court, I bribe the judge.\n\nSuddenly you don't like the free market.\n\nYou say, no, no, no, no, no.\n\nCourt should not be a free market.\n\nIt shouldn't be the case that the judge ruled in favor\n\nof whoever gives the judge most money.\n\nIn that situation, you don't like the free market so much.\n\nHmm. There is always\n\nsome kind of sub stratum of trust.\n\nI see. Which is\n\nessential for any competition,\n\nNegative scenarios about democracy becoming populism\n\nor authoritarianism.\n\nYes. But would\n\nyou think about the positive side\n\nof, you know, using AI\n\nto encourage the more trust network?\n\nMore democracies.\n\nIs there like any path we could make, we could use,\n\nyou know, like those new technology to enhance a democracy?\n\nAbsolutely. I mean, we've seen for instance\n\nthat in social media there are algorithms\n\nthat deliberately spread fake news and misinformation\n\nand conspiracy theories\n\nand destroyed trust between people,\n\nwhich resulted in a crisis of democracy.\n\nBut the algorithms don't have to spread fake news\n\nand conspiracy theories.\n\nThey did it because they were designed in a certain way.\n\nThe goal that was given to the algorithms\n\nof social media platforms like Facebook or YouTube\n\nor TikTok, was to increase engagement, maximize engagement.\n\nThis was the goal of the algorithms.\n\nAnd the algorithms discovered by trial\n\nand error that the easiest way\n\nto maximize engagement is by spreading hate\n\nand anger and greed.\n\nBecause these are the things that make people very,\n\nvery engaged.\n\nWhen you are angry about something, you want\n\nto read more about it\n\nand you tell it to other people, there is more engagement.\n\nIf you give the algorithms a different goal, for instance,\n\nincreased trust\n\nor increase truthfulness,\n\nthen they will not spread all these fake news.\n\nThey can be helpful for building a good society,\n\na good democratic society.\n\nAnother very important thing is\n\nthat democracy should be a conversation\n\nbetween human beings.\n\nI see. For that,\n\nyou need to know, you need to trust\n\nthat you are talking with another human being.\n\nIncreasingly on social media\n\nor generally on the internet, you don't know if\n\nwhat you are reading is something\n\nthat a human being has written\n\nand is spreading or is it a bot?\n\nThis destroys trust between humans\n\nand makes democracy much more difficult.\n\nBut we can have a regulation, a law that bans bots\n\nand ais from masquerading as human beings.\n\nIf you see some story on Twitter, you need\n\nto know if this is being promoted\n\nby a human being or by a bot.\n\nAnd if people say, but what about freedom of speech?\n\nWell, bots don't have freedom of speech.\n\nI mean, we don't need to.\n\nI'm very much against censoring\n\nthe expression of human beings.\n\nBut this doesn't protect the expression of bots.\n\nI see.\n\nBots don't have freedom of speech.\n\nAnd that context, I remember that some\n\nof the one big company in Japan trying\n\nto make the AI constellation, you know, just connecting AI\n\nand even just connect with human being and ai.\n\nYeah. And it just let them\n\nto discuss something important like,\n\nlike a multi-stakeholder democracies.\n\nYes. So AI\n\nwill declare they're ai.\n\nAnd they have really different intelligence like\n\nalien intelligence.\n\nAnd would you think, you know,\n\nin the near future human being will have a discussion\n\nwith alien intelligence would make us wiser.\n\nAbsolutely.\n\nBecause yes,\n\nais on the one hand can be very creative\n\nand can come up with ideas that wouldn't occur to us.\n\nSo talking with an AI can make us wiser.\n\nBut ais can also flood us with enormous amounts\n\nof junk and of misleading information,\n\nand they can manipulate us.\n\nAnd the thing about AI is that, you know, as members\n\nof society, we are stakeholders.\n\nFor instance, the, the, the, the sewage system.\n\nWe need the sewage system\n\nbecause we have bodies we can become sick.\n\nYeah. If the\n\nsewage system collapses, then diseases like dysentery\n\nand cholera spread, this is not a threat to ai.\n\nFor the ai it doesn't care if the sewage system collapses.\n\nIt cannot become sick, it cannot die, doesn't care about it.\n\nWe need to remember it's not a human being.\n\nIt's not even an organic being.\n\nIts interests, its worldview are alien to us.\n\nWhen you talk with people you know,\n\nlike we are now talking to each other,\n\nthe fact that we are physically\n\nbeings is very, very clear.\n\nUltimately, they also has a physical existence\n\nbecause ai, they don't exist in some kind\n\nof mental field.\n\nThey exist in a network of computers\n\nand servers and and so forth.\n\nSo they also have physical existence, but it's not organic.\n\nSo what is most important things\n\nfor you when you think about future?\n\nHmm.\n\nI think the two key issues,\n\none we've covered a lot, which is the issue of trust.\n\nIf we can strengthen trust between humans,\n\nwe will also be able to manage the AI revolution.\n\nThe other thing is the, the fear, the threat.\n\nI mean, throughout history people live their lives\n\ninside you can say a cultural cocoon made\n\nof poems and legends\n\nand mythologies, ideologies, money, all\n\nof them came from the human mind.\n\nNow increasingly,\n\nall these cultural products will come from a\n\nnon-human intelligence.\n\nAnd we might find ourselves entrapped\n\ninside such an alien world\n\nand lose touch with reality\n\nbecause AI can flood us with all these new illusions\n\nthat don't even come from the human intelligence,\n\nfrom the human imagination.\n\nSo it's very difficult for us to understand this illusion.\n\nI see.\n\nThank you very much for all the interviews.\n\nThank you. It's really inspiring\n\nand a great message even for Japanese readership.\n\nAnd Wired Japanese readership too.",
  "authors": [
    "Cond√© Nast"
  ],
  "url": "https://www.wired.com/video/watch/big-interview-the-big-interview-yuval-noah-harari"
}
{
  "title": "Cryogenics, AI Avatars, and The Future of Dying",
  "text": "Transcript\n\nImmortality and the ability to communicate\n\nwith the dead have been something\n\nthat humans have always strived for.\n\nToday, we'll break down the ways technology\n\nis reshaping the afterlife.\n\nThis is Incognito Mode.\n\n[mysterious music]\n\n[keyboard keys tapping] [soft dark music]\n\nLet's just address the elephant in the room.\n\nYes, people are freezing their bodies\n\nso that they might be defrosted at some later date\n\nand go on living.\n\nNo, Walt Disney isn't one of them,\n\nbut there are around 600 people worldwide\n\nwho have chosen to be cryopreserved\n\nso that they can be defrosted at some later date\n\nwhen medical technology has advanced to the point\n\nwhere whatever was ailing them could be cured.\n\nSo, how does cryonics work?\n\nOnce a person is legally declared dead,\n\ntheir body is slowly cooled in an ice bath.\n\nIt's then pumped full of antifreeze in attempt\n\nto rid the body of all water,\n\nwhich will help protect the cells\n\nduring the freezing process.\n\nOnce the body reaches -200 degrees Celsius,\n\nit's moved into what's called a cryostat,\n\nwhich is a liquid nitrogen freezer,\n\nand that's where the body remains.\n\nThe first person was cryogenically frozen in the 1960s,\n\nand new companies promising this technology\n\nare still popping up.\n\nThe cost of being cryopreserved ranges\n\nfrom around $30,000 up to around $200,000.\n\nSo, is this all just a scam?\n\nIs this technology even real?\n\nDoes it work?\n\nScientists have been able to successfully unfreeze\n\nsingle cells and even embryos,\n\nand people who have suffered extreme cold conditions\n\nand had their organs nearly freeze\n\nhave been successfully revived.\n\n[Reporter] 26-year-old Justin Smith\n\nis grateful to be alive after nearly freezing to death.\n\nThe process of bringing back an entire human body\n\nmade up of 40 trillion cells\n\nis an entirely different undertaking.\n\nTo date, there's not been a single person\n\nwho's been cryogenically preserved,\n\nwho's been successfully defrosted, and brought back to life,\n\nand scientists don't even believe it's on the horizon.\n\n[keyboard keys tapping] [mysterious music]\n\nAdvancements in artificial intelligence\n\nhave made the replication of human existence\n\nmore possible than ever.\n\nThese technologies are now being used\n\nto memorialize people in new ways.\n\nAt this time, the death tech industry\n\nis estimated to be worth roughly $125 billion globally.\n\nA large portion of the death tech industry\n\nare companies that use AI to recreate people\n\nin either text, image, or voice form.\n\nWe can discuss my childhood in Tracy,\n\nteenage years in Oakland, or about going to Cal.\n\nGrief bots are the most basic of these technologies.\n\nThey can be based on text\n\nthat's out there in the public domain,\n\nbut more sophisticated ones can have private conversations\n\nlike emails, text messages,\n\nor other writing uploaded to create the chatbot.\n\nHave you had any good meals lately?\n\n[laughs] This is so accurate\n\nbecause he would so often ignore\n\nwhat I asked him that he asked\n\nme his own question. [person laughs]\n\nA more advanced version of this technology are AI avatars,\n\nwhich are image recreations of someone's likeness.\n\n[person singing in foreign language]\n\nNow she's singing Happy Birthday.\n\n[Person] Mm.\n\nAI avatars allow someone to have, say, a FaceTime call\n\nwith the deceased or even create new videos with them.\n\n[Reporter] Five years ago,\n\nshe featured in a documentary [child speaks in Korean]\n\nthat let her meet a virtual reality version of her daughter.\n\n[mother sniffling]\n\n[mother speaks in Korean] It was a chance\n\nfor a final goodbye. [child speaks in Korean]\n\nWe've already seen AI avatars of the deceased\n\nused in new and novel ways.\n\nIn May of 2025, Christopher Pelkey appeared in court\n\nmore than three years after his death\n\nwhen he was shot during a road rage incident.\n\nPelkey's family wanted him\n\nto be accurately represented in court,\n\nso they had his AI avatar give a statement\n\nin what they believed would be his own words.\n\nJust to be clear for everyone seeing this,\n\nI'm a version of Chris Pelkey recreated through AI\n\nthat uses my picture and my voice profile.\n\nThe man ultimately convicted\n\nof killing Pelkey was sentenced to 10.5 years in prison,\n\nthe maximum sentence\n\nand beyond the nine years prosecutor sought.\n\nBut I love the beauty in what Christopher,\n\nand I call him Christopher.\n\nI always call people by their last names,\n\nit's a formality of the court,\n\nbut I feel like calling him Christopher\n\nas we've gotten to know him today.\n\nI feel that that was genuine.\n\nIn another instance,\n\njournalist and former CNN correspondent,\n\nJim Acosta, recently had a conversation\n\nwith an AI avatar of Joaquin Oliver,\n\none of 17 people killed in the Marjory Stoneman\n\nDouglas School shooting in Parkland, Florida in 2018.\n\nJoaquin's avatar was created using a photo\n\nwhich was fed into artificial intelligence\n\nto create his image.\n\nAcosta asked Joaquin's avatar about his death\n\nand about gun laws in the United States,\n\nand the avatar answered with what would be presumed\n\nto be Joaquin's own words.\n\nI believe in a mix of stronger gun control laws,\n\nmental health support, and community engagement.\n\nWe need to create safe spaces\n\nfor conversations and connections,\n\nmaking sure everyone feels seen and heard.\n\nThe most advanced version of these AI recreations\n\ninvolves creating avatars in advance.\n\nThat means going into a studio, recording lots of footage,\n\neven 3D images, answering long questionnaires\n\nwith specific questions to recreate this person\n\nin a much more realistic way.\n\n[person speaking in foreign language]\n\nThese services are reported to cost around $10,000.\n\n[dark electro music]\n\n[keyboard keys tapping]\n\nWhile recreating someone you've lost might sound great,\n\nat least for some people in some situations,\n\nthere's definitely some downsides you need to consider.\n\nThe first is that the death tech industry is an industry.\n\nAt least in the United States,\n\nAI is really under-regulated.\n\nCompanies misbehave and make mistakes all the time,\n\nand the death industry is no different.\n\nExperts are already warning about AI hauntings,\n\nwhere people could get spammed\n\nwith messages from deceased loved ones\n\nthat they really don't wanna see,\n\nand that can be really distressing.\n\nThere's little stopping companies\n\nfrom using a deceased loved one's data\n\nfor marketing purposes or using\n\ntheir likeness in advertising.\n\nThe mental health impacts of AI avatars remains unknown,\n\nbut psychologists warn that it might not be a great idea\n\nto continue having a relationship\n\nwith someone who has passed,\n\nand we don't know what the consequences of that could be.\n\nWhile having access to an AI avatar\n\nof a lost loved one might be comforting at times,\n\npsychologists warn that it could prolong the grief process\n\nor limit the ability to accept the loss\n\nand the long-term impacts of that\n\ncould be really detrimental.\n\nWe've already seen the impacts\n\nof people using generic chatbots to confide in\n\nand confess their deepest issues to,\n\nand in some instances,\n\nthose have allegedly been linked to suicides.\n\n[Reporter] The bot offering to help Adam\n\nwith writing a suicide note\n\nand providing step-by-step instructions\n\nfor the hanging method Adam used.\n\nCreating a grief bot\n\nor another AI avatar of a lost loved one\n\nand chatting with them during a period of grief\n\ncould potentially increase the risks\n\nassociated with using this technology.\n\nWhen we try to use technology\n\nto remove these hard experiences,\n\nit never really works the way\n\nthat we fantasize that it will.\n\nIt can't take away our pain,\n\nit can't take away the sting of loss,\n\nand eventually, maybe we get to the point\n\nwhere we realize that's okay.\n\n[keyboard keys tapping] [suspenseful music]\n\nThe debate around AI avatars of people\n\nwho have recently passed,\n\nit's become most high profile in the world of entertainment.\n\nWe've seen various projects involving the reincarnation\n\nof Marilyn Monroe in a digital form.\n\n♪ Ba, dum, ba, dum ♪\n\n♪ Ba, doodly, dum ♪\n\nPoo!\n\n[Andrew] We even have a robot of Suzanne Somers.\n\nIt always makes my day connect\n\nwith wonderful people that I do-\n\nThose people obviously wouldn't have given the consent\n\nto have an AI avatar of themselves created\n\nbecause that technology didn't exist in their lifetimes.\n\nAnd for actors and other celebrities who are alive now,\n\nthey're having to consider the implications\n\nof their likenesses being used in ways\n\nthey might not expect.\n\nYou can imagine an actor not wanting\n\nto have their likeness involved in a project\n\nthat they don't agree with or one that just flops,\n\nor having them say something\n\nthat they really would never wanna say.\n\nThere's the issue of rights and consent.\n\nWho owns the rights to your avatar,\n\nand how do you know that some Hollywood exec\n\nisn't gonna just sign you up for a bunch of B movies\n\nand tarnish your reputation in your legacy?\n\nThese are already issues celebrities have had to confront.\n\nFor example, before his death in 2024,\n\nactor James Earl Jones consented\n\nto having his voice preserved and recreated\n\nfor the purposes of keeping the character\n\nof Darth Vader alive.\n\nIn contrast, celebrity chef Anthony Bourdain\n\ndidn't take steps to ensure how his digital likeness\n\nmight be used in the afterlife.\n\nAs a result, Bourdain's voice was cloned\n\nto create short clips of him reading his writing\n\nwithout his consent for a 2021 documentary about his life.\n\n[Anthony] And I'm wondering, are you happy?\n\n[Reporter] That soundbite was something Bourdain wrote\n\nbut never actually said.\n\nThe voice was generated by a computer.\n\nBecause of the consent issues\n\nand the fact that the use of voice clone\n\nwasn't initially disclosed,\n\nmany people felt deceived by the filmmaker's choice.\n\nTo do that and then not disclose\n\nthat you've done it is a colossal bad idea.\n\nThese are questions that celebrities\n\nare having to ask right now,\n\nbut it's also ones that we're gonna have to consider\n\nas this technology becomes more democratized\n\nand the rise of death, tech becomes more normalized.\n\n[keyboard keys tapping] [dark music]\n\nRegardless of what you think about death tech,\n\nyou're already being immortalized\n\nby the data you're creating right now.\n\nWhile we've long thought about our physical possessions,\n\nyour digital footprint is increasingly becoming\n\na huge part of what you leave behind.\n\nOne of the early instances of tech companies grappling\n\nwith this was in 2009 when Facebook began memorializing\n\nthe pages of users who had died.\n\nWe've since seen companies from Apple to Google to Amazon\n\ncreate mechanisms for people to manage accounts\n\nafter someone passes away.\n\nStill, the process of gaining access\n\nto a deceased loved one's account\n\nor otherwise managing their online life\n\nisn't always straightforward\n\nand can involve a lot of bureaucratic steps,\n\nbut it's understandable why there might be hurdles\n\nfor getting control of somebody's account.\n\nYou can imagine the security and privacy issues that come up\n\nif this process wasn't so closely managed.\n\n[keyboard keys tapping] [mysterious music]\n\nSo, how do you deal with a future in which it's possible\n\nfor someone to live forever in a digital existence?\n\nIt might be surprising,\n\nbut one of the best things that you can do is to make sure\n\nthat you are addressing your digital life in your will.\n\nMake sure that you're really clear\n\nabout what you want to have happen to your data\n\nand your accounts so that there's no ambiguity\n\nabout what to do with your data.\n\nIf you don't have a will,\n\nand let's be honest, not everybody does,\n\none of the important things that you can do\n\nis talk about these issues with your family\n\nand other loved ones so that they can know\n\nwhat you think about these issues and what you might want.\n\nFinally, if you're concerned about someone\n\ncreating an AI avatar of you without your consent,\n\nlimit the amount of data\n\nthat's out there about you publicly.\n\nThat means social media posts, YouTube videos,\n\nand anything else that could be fed into an AI system\n\nand create a digital you.\n\nThis has been Incognito Mode.\n\nUntil next time.\n\n[soft synth music]",
  "authors": [
    "Condé Nast"
  ],
  "url": "https://www.wired.com/video/watch/incognito-mode-incognito-mode-the-future-of-death"
}